# -*- coding: utf-8 -*-
"""Diabetes Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OJL1quu-DPYs2ZBORZKVZnvGCh68zStk

importing the dependencies
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd

from sklearn.cluster import KMeans
from matplotlib import pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.preprocessing import MinMaxScaler
# %matplotlib inline

"""Data Collection and Analysis

PIMA Diabetes Dataset
"""

# loading dataset to pandas dataframe
diabetes_dataset = pd.read_csv('/content/diabetes.csv')

pd.read_csv?

#printing first 5 rows of dataset
df1=diabetes_dataset.head()
print(df1)

df2=diabetes_dataset.tail()
print(df2)

inner= pd.merge(df1, df2)
print(inner)

#number of rows and columns in this dataset
diabetes_dataset.shape

# getting the statistical measure of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()

"""0--> Non-Diabetic

1--> Diabetic
"""

diabetes_dataset.groupby('Outcome').mean()

# separating the data and labels
X= diabetes_dataset.drop(columns= 'Outcome', axis=1)
Y= diabetes_dataset['Outcome']

print(X)

print(Y)

"""Data Standardization"""

scaler = StandardScaler()

scaler.fit(X)

standardize_data = scaler.transform(X)

print(standardize_data)

X= standardize_data
Y= diabetes_dataset['Outcome']

print(X)
print(Y)

"""Train Test Split"""

X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""Training The Model"""

classifier= svm.SVC(kernel='linear')

# training the suport vector machine Classifer
classifier.fit(X_train,Y_train)

"""Evaluate the Model

Accuracy Score
"""

# accuracy score on the trainig data
X_train_prediction= classifier.predict(X_train)
training_data_accuracy= accuracy_score(X_train_prediction, Y_train)

print('Accuracy of the train data: ', training_data_accuracy)

# accuracy score on the test data
X_test_prediction= classifier.predict(X_test)
test_data_accuracy= accuracy_score(X_test_prediction, Y_test)

print('Accuracy of the test data: ', test_data_accuracy)

"""Making a Predictive system"""

input_data= (10,115,0,0,0,35.3,0.134,29)

#changing the input data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

#reshape the array as we are predicting for one instace
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standerdize the input data
#std_data = scaler.transform(input_data_reshaped)
#print(std_data)

predection = classifier.predict(input_data_reshaped)
print(predection)
if(predection[0]==0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

"""Visualization"""

diabetes_dataset.head()

plt.figure(figsize=(15,10))
plt.plot(diabetes_dataset["Glucose"])
plt.show()

diabetes_dataset.head()

plt.scatter(diabetes_dataset['Glucose'], diabetes_dataset['Age'])

km=KMeans(n_clusters=3)
km

y_predicted=km.fit_predict(diabetes_dataset[['Glucose','Age']])
y_predicted

diabetes_dataset['cluster']=y_predicted
diabetes_dataset.head()

df3=diabetes_dataset[diabetes_dataset.cluster==0]
df4=diabetes_dataset[diabetes_dataset.cluster==1]
df5=diabetes_dataset[diabetes_dataset.cluster==2]

plt.scatter(df3.Glucose,df3['Age'],color='green')
plt.scatter(df4.Glucose,df4['Age'],color='red')
plt.scatter(df5.Glucose,df5['Age'],color='black')

plt.xlabel('Glucose')
plt.ylabel('Age')
plt.legend()

diabetes_dataset.head()

A=diabetes_dataset['cluster']
diabetes_dataset=diabetes_dataset.drop('cluster', axis=1)
print(diabetes_dataset.head())

confusion_matrix(Y_test, X_test_prediction)

tn, fp, fn, tp= confusion_matrix(Y_test, X_test_prediction).ravel()
(tn, fp, fn, tp)

# Classification Report
from scipy.sparse.sputils import matrix
matrix=classification_report(Y_test, X_test_prediction)
print('Classification Report : \n', matrix)

"""Deploy Model

Saving the trained model
"""

import pickle

filename= 'trained_model_sav'
pickle.dump(classifier, open(filename, 'wb'))

#loading the saved model
loaded_model = pickle.load(open('trained_model_sav', 'rb'))

input_data= (10,115,0,0,0,35.3,0.134,29)

#changing the input data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

#reshape the array as we are predicting for one instace
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standerdize the input data
#std_data = scaler.transform(input_data_reshaped)
#print(std_data)

predection = loaded_model.predict(input_data_reshaped)
print(predection)
if(predection[0]==0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

